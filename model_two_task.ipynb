{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c7c5c86cffba438f9a684d2b814e11ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8392fb618078438e8da503a659d5f89e",
              "IPY_MODEL_6f7a70f4e8e042a0a76eba1fe8e509d7",
              "IPY_MODEL_c56151bb3020431aa7847a548f55576f"
            ],
            "layout": "IPY_MODEL_0fa76f762d844e208d0b4a1508f32e72"
          }
        },
        "8392fb618078438e8da503a659d5f89e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_574cb867df50414a97b3ee863f518a56",
            "placeholder": "​",
            "style": "IPY_MODEL_d486caf3560646b8a02c7c2f00db8970",
            "value": "Map: 100%"
          }
        },
        "6f7a70f4e8e042a0a76eba1fe8e509d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8e5c8dcd20f4ea5bf95de7de952bd7d",
            "max": 10039,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2cd568a4edee4981b31b283712a3321e",
            "value": 10039
          }
        },
        "c56151bb3020431aa7847a548f55576f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdd4fcd7c9894402ad46d160cd5b4499",
            "placeholder": "​",
            "style": "IPY_MODEL_a32fab5341a44f8ba689bee57f56986e",
            "value": " 10039/10039 [00:00&lt;00:00, 96905.31 examples/s]"
          }
        },
        "0fa76f762d844e208d0b4a1508f32e72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "574cb867df50414a97b3ee863f518a56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d486caf3560646b8a02c7c2f00db8970": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8e5c8dcd20f4ea5bf95de7de952bd7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cd568a4edee4981b31b283712a3321e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cdd4fcd7c9894402ad46d160cd5b4499": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a32fab5341a44f8ba689bee57f56986e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54ec786571fc48f1802aaecf93409bf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eec3b6f8bcda4b2eaf68a0b77c7a413b",
              "IPY_MODEL_9011e06c1c194bb3a9683d5fa9af1fdb",
              "IPY_MODEL_a17eaed653d64a26b068837fe4ada406"
            ],
            "layout": "IPY_MODEL_2a816e5890d442d38720b9c1afe276d9"
          }
        },
        "eec3b6f8bcda4b2eaf68a0b77c7a413b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_593e338785c84dce927a88620d74ed71",
            "placeholder": "​",
            "style": "IPY_MODEL_e3e1ae18eaf24eadab4501d49d28f1f4",
            "value": "Map: 100%"
          }
        },
        "9011e06c1c194bb3a9683d5fa9af1fdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed322aa0be15435d813a740a10442a6e",
            "max": 6261,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5417dac86fcc49d5b4ba24a0d650e93f",
            "value": 6261
          }
        },
        "a17eaed653d64a26b068837fe4ada406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4751f1da060943e7a039968cf0e92c95",
            "placeholder": "​",
            "style": "IPY_MODEL_e6cd25382bd94a5ca2851c0e4ed3e036",
            "value": " 6261/6261 [00:00&lt;00:00, 70009.43 examples/s]"
          }
        },
        "2a816e5890d442d38720b9c1afe276d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "593e338785c84dce927a88620d74ed71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3e1ae18eaf24eadab4501d49d28f1f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed322aa0be15435d813a740a10442a6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5417dac86fcc49d5b4ba24a0d650e93f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4751f1da060943e7a039968cf0e92c95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6cd25382bd94a5ca2851c0e4ed3e036": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afc4be00c6b146f49eb9ef44b5f2e1ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_68bd2d2c0eec47f3b0c25d194fcf8c98",
              "IPY_MODEL_62e40b5ae8404959bfac95e80f8fdf6e",
              "IPY_MODEL_94343271cf6043fab5ae13ddba0a01a6"
            ],
            "layout": "IPY_MODEL_e5012495a3da46d681e39fa1496762e2"
          }
        },
        "68bd2d2c0eec47f3b0c25d194fcf8c98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13dab129701a4f0f85732415ec89d4b0",
            "placeholder": "​",
            "style": "IPY_MODEL_8b0e2bdb6c72490e8e2944af73f6917a",
            "value": "Filter: 100%"
          }
        },
        "62e40b5ae8404959bfac95e80f8fdf6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87b13601ac8b4e21a671c9c73cca6f97",
            "max": 10039,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61345534f8e64c16aa550f0adb14aba4",
            "value": 10039
          }
        },
        "94343271cf6043fab5ae13ddba0a01a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1eb370cfb56945b9b3651a4692e9269d",
            "placeholder": "​",
            "style": "IPY_MODEL_06035622c9a948f2a9ae25da9ec95622",
            "value": " 10039/10039 [00:00&lt;00:00, 81843.22 examples/s]"
          }
        },
        "e5012495a3da46d681e39fa1496762e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13dab129701a4f0f85732415ec89d4b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b0e2bdb6c72490e8e2944af73f6917a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87b13601ac8b4e21a671c9c73cca6f97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61345534f8e64c16aa550f0adb14aba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1eb370cfb56945b9b3651a4692e9269d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06035622c9a948f2a9ae25da9ec95622": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Annesya/voice-speech-metamers/blob/master/model_two_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install speechbrain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2xxj-Oqfelf",
        "outputId": "2b52b05b-388a-4ffc-87d6-ab2372e0f55a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: speechbrain in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from speechbrain) (24.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.11.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from speechbrain) (0.1.99)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from speechbrain) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from speechbrain) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from speechbrain) (4.66.2)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from speechbrain) (0.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.9->speechbrain) (12.4.127)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->speechbrain) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->speechbrain) (2.31.0)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.28 in /usr/local/lib/python3.10/dist-packages (from hyperpyyaml->speechbrain) (0.18.6)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain) (0.2.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->speechbrain) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9->speechbrain) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install datasets -U\n",
        "!pip install librosa\n",
        "!pip install jiwer"
      ],
      "metadata": {
        "id": "IwORGsfYf-qZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from speechbrain.inference.speaker import EncoderClassifier\n",
        "import torch\n",
        "from collections import defaultdict\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import Compose\n",
        "from transformers import WhisperForConditionalGeneration, WhisperProcessor, AutoFeatureExtractor, WhisperModel, WhisperTokenizer\n",
        "from datasets import load_dataset, DatasetDict, Audio, load_metric"
      ],
      "metadata": {
        "id": "t5T6u3TCgsH8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***DATA*** ***PREPARATION***"
      ],
      "metadata": {
        "id": "prrxpM5CmlI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "common_voice = DatasetDict()\n",
        "\n",
        "common_voice_train = load_dataset(\"fsicoli/common_voice_17_0\", \"ja\", split=\"train\")\n",
        "common_voice_test = load_dataset(\"fsicoli/common_voice_17_0\", \"ja\", split=\"test\")\n",
        "\n",
        "print(common_voice)"
      ],
      "metadata": {
        "id": "fYlxS9PSg3HS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95e9bbd0-3133-448a-a80b-b3181a73230c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1486: FutureWarning: The repository for fsicoli/common_voice_17_0 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/fsicoli/common_voice_17_0\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    \n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "common_voice_train = common_voice_train.remove_columns([\"accent\", \"age\", \"down_votes\", \"gender\", \"locale\", \"segment\", \"up_votes\"])\n",
        "common_voice_test = common_voice_test.remove_columns([\"accent\", \"age\", \"down_votes\", \"gender\", \"locale\", \"segment\", \"up_votes\"])"
      ],
      "metadata": {
        "id": "JjHIEyBhB3RF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "common_voice_train = common_voice_train.cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
        "common_voice_test = common_voice_test.cast_column(\"audio\", Audio(sampling_rate=16_000))"
      ],
      "metadata": {
        "id": "RJtpg1L2B_WJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Word Vocabulary Processing***"
      ],
      "metadata": {
        "id": "fgUCzX0gr6d3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "chars_to_remove_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\“\\%\\‘\\”\\�\\'\\⋯\\、\\。\\《\\》\\「\\」\\！\\（\\）\\，\\：\\；\\？\\～\\|]'\n",
        "# Feel free to add more unwanted symbols\n",
        "\n",
        "def remove_special_characters(batch):\n",
        "    batch[\"sentence\"] = re.sub(chars_to_remove_regex, '', batch[\"sentence\"]).lower()\n",
        "    return batch"
      ],
      "metadata": {
        "id": "vCZxOv3tr5wM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "common_voice_train = common_voice_train.map(remove_special_characters)\n",
        "common_voice_test = common_voice_test.map(remove_special_characters)"
      ],
      "metadata": {
        "id": "6vgAXDP8sNel"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Inlcude text normalization if needed"
      ],
      "metadata": {
        "id": "JN4-SqYNsa44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_all_chars(batch):\n",
        "  all_text = \" \".join(batch[\"sentence\"])\n",
        "  vocab = list(set(all_text))\n",
        "  return {\"vocab\": [vocab], \"all_text\": [all_text]}"
      ],
      "metadata": {
        "id": "X6lXCpHdsax8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_train = common_voice_train.map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True, remove_columns=common_voice_train.column_names)\n",
        "vocab_test = common_voice_test.map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True, remove_columns=common_voice_test.column_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "c7c5c86cffba438f9a684d2b814e11ba",
            "8392fb618078438e8da503a659d5f89e",
            "6f7a70f4e8e042a0a76eba1fe8e509d7",
            "c56151bb3020431aa7847a548f55576f",
            "0fa76f762d844e208d0b4a1508f32e72",
            "574cb867df50414a97b3ee863f518a56",
            "d486caf3560646b8a02c7c2f00db8970",
            "e8e5c8dcd20f4ea5bf95de7de952bd7d",
            "2cd568a4edee4981b31b283712a3321e",
            "cdd4fcd7c9894402ad46d160cd5b4499",
            "a32fab5341a44f8ba689bee57f56986e",
            "54ec786571fc48f1802aaecf93409bf4",
            "eec3b6f8bcda4b2eaf68a0b77c7a413b",
            "9011e06c1c194bb3a9683d5fa9af1fdb",
            "a17eaed653d64a26b068837fe4ada406",
            "2a816e5890d442d38720b9c1afe276d9",
            "593e338785c84dce927a88620d74ed71",
            "e3e1ae18eaf24eadab4501d49d28f1f4",
            "ed322aa0be15435d813a740a10442a6e",
            "5417dac86fcc49d5b4ba24a0d650e93f",
            "4751f1da060943e7a039968cf0e92c95",
            "e6cd25382bd94a5ca2851c0e4ed3e036"
          ]
        },
        "id": "3ueD6tfrsapf",
        "outputId": "778af9a9-224e-4524-f49e-8e67c1b451ee"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10039 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7c5c86cffba438f9a684d2b814e11ba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/6261 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54ec786571fc48f1802aaecf93409bf4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_list = list(set(vocab_train[\"vocab\"][0]) | set(vocab_test[\"vocab\"][0]))\n",
        "vocab_dict = {v: k for k, v in enumerate(sorted(vocab_list))}\n",
        "print(len(vocab_dict))\n",
        "print()\n",
        "print(vocab_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wj9FL3ypu5Hk",
        "outputId": "6806265d-126b-4fc8-e12c-48042b8766e0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2610\n",
            "\n",
            "{' ': 0, '&': 1, '(': 2, ')': 3, '/': 4, '[': 5, ']': 6, 'a': 7, 'b': 8, 'c': 9, 'd': 10, 'e': 11, 'f': 12, 'g': 13, 'h': 14, 'i': 15, 'j': 16, 'k': 17, 'l': 18, 'm': 19, 'n': 20, 'o': 21, 'p': 22, 'q': 23, 'r': 24, 's': 25, 't': 26, 'u': 27, 'v': 28, 'w': 29, 'x': 30, 'y': 31, 'z': 32, '–': 33, '—': 34, '―': 35, '’': 36, '…': 37, '☆': 38, '♡': 39, '々': 40, '〇': 41, '〈': 42, '〉': 43, '『': 44, '』': 45, '〜': 46, 'ぁ': 47, 'あ': 48, 'ぃ': 49, 'い': 50, 'ぅ': 51, 'う': 52, 'ぇ': 53, 'え': 54, 'ぉ': 55, 'お': 56, 'か': 57, 'が': 58, 'き': 59, 'ぎ': 60, 'く': 61, 'ぐ': 62, 'け': 63, 'げ': 64, 'こ': 65, 'ご': 66, 'さ': 67, 'ざ': 68, 'し': 69, 'じ': 70, 'す': 71, 'ず': 72, 'せ': 73, 'ぜ': 74, 'そ': 75, 'ぞ': 76, 'た': 77, 'だ': 78, 'ち': 79, 'っ': 80, 'つ': 81, 'づ': 82, 'て': 83, 'で': 84, 'と': 85, 'ど': 86, 'な': 87, 'に': 88, 'ぬ': 89, 'ね': 90, 'の': 91, 'は': 92, 'ば': 93, 'ぱ': 94, 'ひ': 95, 'び': 96, 'ぴ': 97, 'ふ': 98, 'ぶ': 99, 'ぷ': 100, 'へ': 101, 'べ': 102, 'ぺ': 103, 'ほ': 104, 'ぼ': 105, 'ぽ': 106, 'ま': 107, 'み': 108, 'む': 109, 'め': 110, 'も': 111, 'ゃ': 112, 'や': 113, 'ゅ': 114, 'ゆ': 115, 'ょ': 116, 'よ': 117, 'ら': 118, 'り': 119, 'る': 120, 'れ': 121, 'ろ': 122, 'ゎ': 123, 'わ': 124, 'を': 125, 'ん': 126, 'ゝ': 127, 'ゞ': 128, 'ァ': 129, 'ア': 130, 'ィ': 131, 'イ': 132, 'ゥ': 133, 'ウ': 134, 'ェ': 135, 'エ': 136, 'ォ': 137, 'オ': 138, 'カ': 139, 'ガ': 140, 'キ': 141, 'ギ': 142, 'ク': 143, 'グ': 144, 'ケ': 145, 'ゲ': 146, 'コ': 147, 'ゴ': 148, 'サ': 149, 'ザ': 150, 'シ': 151, 'ジ': 152, 'ス': 153, 'ズ': 154, 'セ': 155, 'ゼ': 156, 'ソ': 157, 'ゾ': 158, 'タ': 159, 'ダ': 160, 'チ': 161, 'ッ': 162, 'ツ': 163, 'ヅ': 164, 'テ': 165, 'デ': 166, 'ト': 167, 'ド': 168, 'ナ': 169, 'ニ': 170, 'ヌ': 171, 'ネ': 172, 'ノ': 173, 'ハ': 174, 'バ': 175, 'パ': 176, 'ヒ': 177, 'ビ': 178, 'ピ': 179, 'フ': 180, 'ブ': 181, 'プ': 182, 'ヘ': 183, 'ベ': 184, 'ペ': 185, 'ホ': 186, 'ボ': 187, 'ポ': 188, 'マ': 189, 'ミ': 190, 'ム': 191, 'メ': 192, 'モ': 193, 'ャ': 194, 'ヤ': 195, 'ュ': 196, 'ユ': 197, 'ョ': 198, 'ヨ': 199, 'ラ': 200, 'リ': 201, 'ル': 202, 'レ': 203, 'ロ': 204, 'ワ': 205, 'ン': 206, 'ヴ': 207, 'ヵ': 208, 'ヶ': 209, '・': 210, 'ー': 211, '一': 212, '丁': 213, '七': 214, '万': 215, '丈': 216, '三': 217, '上': 218, '下': 219, '不': 220, '与': 221, '世': 222, '丘': 223, '両': 224, '並': 225, '中': 226, '串': 227, '丸': 228, '丹': 229, '主': 230, '丼': 231, '久': 232, '之': 233, '乏': 234, '乗': 235, '乙': 236, '九': 237, '乞': 238, '也': 239, '乱': 240, '乳': 241, '乾': 242, '亀': 243, '了': 244, '予': 245, '争': 246, '事': 247, '二': 248, '云': 249, '互': 250, '五': 251, '井': 252, '些': 253, '亜': 254, '亡': 255, '交': 256, '京': 257, '亭': 258, '人': 259, '仁': 260, '今': 261, '介': 262, '仏': 263, '仕': 264, '他': 265, '付': 266, '仙': 267, '代': 268, '令': 269, '以': 270, '仮': 271, '仰': 272, '仲': 273, '件': 274, '任': 275, '企': 276, '伊': 277, '伍': 278, '伎': 279, '伏': 280, '伐': 281, '休': 282, '会': 283, '伝': 284, '伯': 285, '伴': 286, '伸': 287, '似': 288, '但': 289, '位': 290, '低': 291, '住': 292, '佐': 293, '体': 294, '何': 295, '余': 296, '作': 297, '併': 298, '使': 299, '例': 300, '供': 301, '依': 302, '価': 303, '侵': 304, '侶': 305, '便': 306, '係': 307, '促': 308, '俄': 309, '俗': 310, '保': 311, '信': 312, '俣': 313, '修': 314, '俯': 315, '俳': 316, '俵': 317, '俺': 318, '倉': 319, '個': 320, '倍': 321, '倒': 322, '候': 323, '借': 324, '倣': 325, '値': 326, '倫': 327, '偉': 328, '偏': 329, '做': 330, '停': 331, '健': 332, '側': 333, '偵': 334, '偶': 335, '偽': 336, '傍': 337, '傑': 338, '傘': 339, '備': 340, '催': 341, '債': 342, '傷': 343, '傾': 344, '僅': 345, '働': 346, '像': 347, '僕': 348, '僚': 349, '僧': 350, '儀': 351, '億': 352, '儘': 353, '儚': 354, '償': 355, '優': 356, '儲': 357, '元': 358, '兄': 359, '充': 360, '兆': 361, '先': 362, '光': 363, '克': 364, '免': 365, '兎': 366, '児': 367, '党': 368, '入': 369, '全': 370, '八': 371, '公': 372, '六': 373, '共': 374, '兵': 375, '其': 376, '具': 377, '典': 378, '兼': 379, '内': 380, '円': 381, '冊': 382, '再': 383, '冑': 384, '冒': 385, '冗': 386, '写': 387, '冠': 388, '冬': 389, '冴': 390, '冶': 391, '冷': 392, '凄': 393, '凍': 394, '凛': 395, '凝': 396, '几': 397, '凡': 398, '処': 399, '凶': 400, '出': 401, '函': 402, '刀': 403, '刃': 404, '分': 405, '切': 406, '刈': 407, '刊': 408, '刑': 409, '列': 410, '初': 411, '判': 412, '別': 413, '利': 414, '到': 415, '制': 416, '刷': 417, '券': 418, '刺': 419, '刻': 420, '剃': 421, '則': 422, '削': 423, '前': 424, '剣': 425, '剤': 426, '剥': 427, '副': 428, '剰': 429, '割': 430, '創': 431, '劇': 432, '力': 433, '功': 434, '加': 435, '劣': 436, '助': 437, '努': 438, '励': 439, '労': 440, '効': 441, '勅': 442, '勇': 443, '勉': 444, '動': 445, '勘': 446, '務': 447, '勝': 448, '募': 449, '勢': 450, '勤': 451, '勧': 452, '勲': 453, '勾': 454, '勿': 455, '匂': 456, '包': 457, '化': 458, '北': 459, '匠': 460, '匹': 461, '区': 462, '医': 463, '匿': 464, '十': 465, '千': 466, '午': 467, '半': 468, '卑': 469, '卒': 470, '卓': 471, '協': 472, '南': 473, '単': 474, '博': 475, '占': 476, '印': 477, '危': 478, '即': 479, '却': 480, '卵': 481, '卿': 482, '厚': 483, '原': 484, '厭': 485, '厳': 486, '去': 487, '参': 488, '又': 489, '及': 490, '友': 491, '双': 492, '反': 493, '収': 494, '叔': 495, '取': 496, '受': 497, '叙': 498, '叡': 499, '口': 500, '古': 501, '句': 502, '叩': 503, '只': 504, '叫': 505, '召': 506, '可': 507, '台': 508, '叱': 509, '史': 510, '右': 511, '叶': 512, '号': 513, '司': 514, '各': 515, '合': 516, '吉': 517, '吊': 518, '同': 519, '名': 520, '后': 521, '吐': 522, '向': 523, '君': 524, '吟': 525, '吠': 526, '否': 527, '含': 528, '吸': 529, '吹': 530, '吾': 531, '呂': 532, '呆': 533, '呈': 534, '呉': 535, '告': 536, '呟': 537, '周': 538, '呪': 539, '味': 540, '呻': 541, '呼': 542, '命': 543, '咋': 544, '和': 545, '咲': 546, '咸': 547, '咽': 548, '哀': 549, '品': 550, '員': 551, '哲': 552, '哺': 553, '唄': 554, '唆': 555, '唇': 556, '唐': 557, '唯': 558, '唱': 559, '唸': 560, '唾': 561, '商': 562, '問': 563, '啓': 564, '善': 565, '喉': 566, '喋': 567, '喚': 568, '喜': 569, '喧': 570, '喩': 571, '喪': 572, '喫': 573, '喰': 574, '営': 575, '嗅': 576, '嘆': 577, '嘉': 578, '嘘': 579, '嘩': 580, '噂': 581, '噌': 582, '噛': 583, '器': 584, '噴': 585, '囚': 586, '四': 587, '回': 588, '因': 589, '団': 590, '困': 591, '囲': 592, '図': 593, '固': 594, '国': 595, '圏': 596, '園': 597, '土': 598, '圧': 599, '在': 600, '地': 601, '坂': 602, '均': 603, '坊': 604, '坐': 605, '坪': 606, '垂': 607, '型': 608, '垢': 609, '垣': 610, '埃': 611, '埋': 612, '城': 613, '域': 614, '執': 615, '培': 616, '基': 617, '埼': 618, '堂': 619, '堅': 620, '堆': 621, '堕': 622, '堤': 623, '堪': 624, '報': 625, '場': 626, '堵': 627, '堺': 628, '塀': 629, '塁': 630, '塊': 631, '塔': 632, '塗': 633, '塙': 634, '塚': 635, '塞': 636, '塩': 637, '填': 638, '塵': 639, '塹': 640, '境': 641, '墓': 642, '増': 643, '墟': 644, '墨': 645, '壁': 646, '壇': 647, '壊': 648, '壌': 649, '壕': 650, '士': 651, '壬': 652, '壮': 653, '声': 654, '壱': 655, '売': 656, '壷': 657, '壺': 658, '変': 659, '夏': 660, '夕': 661, '外': 662, '多': 663, '夜': 664, '夢': 665, '大': 666, '天': 667, '太': 668, '夫': 669, '央': 670, '失': 671, '奄': 672, '奇': 673, '奈': 674, '奉': 675, '奏': 676, '契': 677, '奥': 678, '奨': 679, '奪': 680, '奮': 681, '女': 682, '奴': 683, '好': 684, '如': 685, '妃': 686, '妄': 687, '妊': 688, '妖': 689, '妙': 690, '妥': 691, '妨': 692, '妬': 693, '妹': 694, '妻': 695, '姉': 696, '始': 697, '姓': 698, '委': 699, '姦': 700, '姫': 701, '姻': 702, '姿': 703, '威': 704, '娘': 705, '娠': 706, '娯': 707, '娼': 708, '婆': 709, '婚': 710, '婦': 711, '婿': 712, '媒': 713, '媛': 714, '嫁': 715, '嫉': 716, '嫌': 717, '嬉': 718, '嬢': 719, '子': 720, '孔': 721, '字': 722, '存': 723, '季': 724, '孤': 725, '学': 726, '孫': 727, '孵': 728, '宅': 729, '宇': 730, '守': 731, '安': 732, '宋': 733, '完': 734, '宍': 735, '宗': 736, '官': 737, '宙': 738, '定': 739, '宛': 740, '宜': 741, '宝': 742, '実': 743, '客': 744, '宣': 745, '室': 746, '宮': 747, '宰': 748, '害': 749, '宴': 750, '家': 751, '容': 752, '宿': 753, '寂': 754, '寄': 755, '密': 756, '富': 757, '寒': 758, '寓': 759, '寛': 760, '寝': 761, '察': 762, '寡': 763, '寧': 764, '審': 765, '寮': 766, '寸': 767, '寺': 768, '対': 769, '寿': 770, '封': 771, '専': 772, '射': 773, '将': 774, '尉': 775, '尊': 776, '尋': 777, '導': 778, '小': 779, '少': 780, '尖': 781, '尚': 782, '尤': 783, '就': 784, '尺': 785, '尻': 786, '尽': 787, '尾': 788, '尿': 789, '局': 790, '居': 791, '屈': 792, '届': 793, '屋': 794, '展': 795, '属': 796, '層': 797, '履': 798, '屯': 799, '山': 800, '岐': 801, '岡': 802, '岩': 803, '岬': 804, '岳': 805, '岸': 806, '峙': 807, '峡': 808, '峰': 809, '島': 810, '崇': 811, '崎': 812, '崖': 813, '崩': 814, '嵐': 815, '嶋': 816, '川': 817, '州': 818, '巡': 819, '巣': 820, '工': 821, '左': 822, '巧': 823, '巨': 824, '巫': 825, '差': 826, '己': 827, '巻': 828, '巾': 829, '市': 830, '布': 831, '帆': 832, '希': 833, '帖': 834, '帝': 835, '帥': 836, '師': 837, '席': 838, '帯': 839, '帰': 840, '帳': 841, '帷': 842, '常': 843, '帽': 844, '幅': 845, '幌': 846, '幕': 847, '幡': 848, '幣': 849, '干': 850, '平': 851, '年': 852, '幸': 853, '幹': 854, '幻': 855, '幼': 856, '幽': 857, '幾': 858, '庁': 859, '広': 860, '庄': 861, '床': 862, '序': 863, '底': 864, '庖': 865, '店': 866, '府': 867, '度': 868, '座': 869, '庫': 870, '庭': 871, '庵': 872, '康': 873, '廃': 874, '廊': 875, '廟': 876, '延': 877, '廷': 878, '建': 879, '廻': 880, '弁': 881, '弊': 882, '式': 883, '弓': 884, '引': 885, '弘': 886, '弟': 887, '弦': 888, '弧': 889, '弩': 890, '弱': 891, '張': 892, '強': 893, '弾': 894, '当': 895, '彗': 896, '彙': 897, '形': 898, '彦': 899, '彩': 900, '彫': 901, '彰': 902, '影': 903, '役': 904, '彼': 905, '往': 906, '征': 907, '径': 908, '待': 909, '律': 910, '後': 911, '徐': 912, '徒': 913, '従': 914, '得': 915, '御': 916, '復': 917, '循': 918, '微': 919, '徳': 920, '徴': 921, '徹': 922, '心': 923, '必': 924, '忍': 925, '志': 926, '忘': 927, '忙': 928, '応': 929, '忠': 930, '快': 931, '念': 932, '怒': 933, '怖': 934, '思': 935, '怠': 936, '急': 937, '性': 938, '怪': 939, '怯': 940, '恋': 941, '恐': 942, '恒': 943, '恥': 944, '恨': 945, '恩': 946, '息': 947, '恰': 948, '恵': 949, '悔': 950, '悟': 951, '悠': 952, '患': 953, '悩': 954, '悪': 955, '悲': 956, '情': 957, '惑': 958, '惚': 959, '惜': 960, '惟': 961, '惨': 962, '惰': 963, '想': 964, '惹': 965, '愉': 966, '意': 967, '愕': 968, '愚': 969, '愛': 970, '感': 971, '慄': 972, '慈': 973, '態': 974, '慌': 975, '慎': 976, '慕': 977, '慢': 978, '慣': 979, '慮': 980, '慰': 981, '憂': 982, '憎': 983, '憐': 984, '憤': 985, '憧': 986, '憩': 987, '憲': 988, '憶': 989, '懇': 990, '懊': 991, '懐': 992, '懸': 993, '懺': 994, '成': 995, '我': 996, '戒': 997, '或': 998, '戚': 999, '戦': 1000, '戯': 1001, '戴': 1002, '戸': 1003, '戻': 1004, '房': 1005, '所': 1006, '扇': 1007, '扉': 1008, '手': 1009, '才': 1010, '打': 1011, '払': 1012, '扮': 1013, '扱': 1014, '扶': 1015, '批': 1016, '承': 1017, '技': 1018, '抄': 1019, '把': 1020, '抑': 1021, '抒': 1022, '投': 1023, '抗': 1024, '折': 1025, '抜': 1026, '択': 1027, '披': 1028, '抱': 1029, '抵': 1030, '抹': 1031, '押': 1032, '抽': 1033, '担': 1034, '拍': 1035, '拐': 1036, '拒': 1037, '拓': 1038, '拗': 1039, '拘': 1040, '招': 1041, '拝': 1042, '拠': 1043, '拡': 1044, '括': 1045, '拭': 1046, '拳': 1047, '拶': 1048, '拷': 1049, '拾': 1050, '持': 1051, '指': 1052, '挑': 1053, '挙': 1054, '挟': 1055, '挨': 1056, '挫': 1057, '振': 1058, '挾': 1059, '挿': 1060, '捉': 1061, '捌': 1062, '捕': 1063, '捧': 1064, '捨': 1065, '捲': 1066, '捻': 1067, '掃': 1068, '授': 1069, '掌': 1070, '排': 1071, '掘': 1072, '掛': 1073, '掟': 1074, '採': 1075, '探': 1076, '接': 1077, '控': 1078, '推': 1079, '措': 1080, '掲': 1081, '掴': 1082, '掻': 1083, '揄': 1084, '描': 1085, '提': 1086, '揚': 1087, '換': 1088, '握': 1089, '揮': 1090, '援': 1091, '揶': 1092, '揺': 1093, '損': 1094, '搬': 1095, '搭': 1096, '携': 1097, '搾': 1098, '摂': 1099, '摘': 1100, '摩': 1101, '撃': 1102, '撒': 1103, '撚': 1104, '撞': 1105, '撤': 1106, '撮': 1107, '撲': 1108, '擁': 1109, '操': 1110, '擦': 1111, '支': 1112, '改': 1113, '攻': 1114, '放': 1115, '政': 1116, '故': 1117, '敏': 1118, '救': 1119, '敗': 1120, '教': 1121, '敢': 1122, '散': 1123, '敦': 1124, '敬': 1125, '数': 1126, '整': 1127, '敵': 1128, '敷': 1129, '文': 1130, '斉': 1131, '斎': 1132, '斑': 1133, '斗': 1134, '料': 1135, '斜': 1136, '斧': 1137, '斬': 1138, '断': 1139, '斯': 1140, '新': 1141, '方': 1142, '於': 1143, '施': 1144, '旅': 1145, '旋': 1146, '族': 1147, '旗': 1148, '既': 1149, '日': 1150, '旦': 1151, '旧': 1152, '早': 1153, '旬': 1154, '旭': 1155, '昂': 1156, '昆': 1157, '昇': 1158, '明': 1159, '昏': 1160, '易': 1161, '昔': 1162, '星': 1163, '映': 1164, '春': 1165, '昧': 1166, '昨': 1167, '昭': 1168, '是': 1169, '昼': 1170, '時': 1171, '晒': 1172, '晩': 1173, '普': 1174, '景': 1175, '晴': 1176, '晶': 1177, '智': 1178, '暇': 1179, '暑': 1180, '暖': 1181, '暗': 1182, '暢': 1183, '暫': 1184, '暮': 1185, '暴': 1186, '曇': 1187, '曖': 1188, '曜': 1189, '曲': 1190, '曳': 1191, '更': 1192, '書': 1193, '曹': 1194, '曽': 1195, '替': 1196, '最': 1197, '月': 1198, '有': 1199, '朋': 1200, '服': 1201, '朗': 1202, '望': 1203, '朝': 1204, '期': 1205, '朦': 1206, '朧': 1207, '木': 1208, '未': 1209, '末': 1210, '本': 1211, '札': 1212, '朴': 1213, '机': 1214, '朽': 1215, '杉': 1216, '材': 1217, '村': 1218, '杖': 1219, '束': 1220, '条': 1221, '来': 1222, '杭': 1223, '杯': 1224, '東': 1225, '杵': 1226, '松': 1227, '板': 1228, '析': 1229, '枕': 1230, '林': 1231, '枚': 1232, '果': 1233, '枝': 1234, '枠': 1235, '枢': 1236, '枯': 1237, '架': 1238, '柄': 1239, '柏': 1240, '染': 1241, '柔': 1242, '柢': 1243, '柱': 1244, '柳': 1245, '柴': 1246, '柵': 1247, '査': 1248, '柿': 1249, '栃': 1250, '栄': 1251, '栓': 1252, '栖': 1253, '栗': 1254, '校': 1255, '株': 1256, '核': 1257, '根': 1258, '格': 1259, '栽': 1260, '桁': 1261, '桂': 1262, '桃': 1263, '案': 1264, '桎': 1265, '桑': 1266, '桜': 1267, '桟': 1268, '桶': 1269, '梁': 1270, '梅': 1271, '梏': 1272, '條': 1273, '梨': 1274, '梯': 1275, '械': 1276, '梱': 1277, '梼': 1278, '棄': 1279, '棋': 1280, '棒': 1281, '棚': 1282, '棟': 1283, '森': 1284, '棲': 1285, '椅': 1286, '植': 1287, '椎': 1288, '検': 1289, '楊': 1290, '楕': 1291, '楚': 1292, '業': 1293, '極': 1294, '楼': 1295, '楽': 1296, '概': 1297, '榛': 1298, '構': 1299, '槍': 1300, '様': 1301, '槻': 1302, '槽': 1303, '標': 1304, '模': 1305, '権': 1306, '横': 1307, '樫': 1308, '樹': 1309, '樽': 1310, '橋': 1311, '橙': 1312, '機': 1313, '橿': 1314, '檜': 1315, '欄': 1316, '欠': 1317, '次': 1318, '欧': 1319, '欲': 1320, '欺': 1321, '歌': 1322, '歎': 1323, '歓': 1324, '止': 1325, '正': 1326, '武': 1327, '歩': 1328, '歪': 1329, '歯': 1330, '歳': 1331, '歴': 1332, '死': 1333, '殉': 1334, '殊': 1335, '残': 1336, '殖': 1337, '殴': 1338, '段': 1339, '殺': 1340, '殻': 1341, '殿': 1342, '毅': 1343, '母': 1344, '毎': 1345, '毒': 1346, '比': 1347, '毛': 1348, '毯': 1349, '氏': 1350, '民': 1351, '気': 1352, '水': 1353, '氷': 1354, '永': 1355, '氾': 1356, '汁': 1357, '求': 1358, '汎': 1359, '汐': 1360, '汗': 1361, '汚': 1362, '汝': 1363, '江': 1364, '池': 1365, '汰': 1366, '汲': 1367, '決': 1368, '汽': 1369, '沃': 1370, '沈': 1371, '沖': 1372, '没': 1373, '沢': 1374, '沫': 1375, '河': 1376, '沸': 1377, '油': 1378, '治': 1379, '沼': 1380, '沿': 1381, '況': 1382, '泉': 1383, '泊': 1384, '泌': 1385, '法': 1386, '泡': 1387, '波': 1388, '泣': 1389, '泥': 1390, '注': 1391, '泰': 1392, '泳': 1393, '洋': 1394, '洒': 1395, '洗': 1396, '洞': 1397, '津': 1398, '洪': 1399, '洲': 1400, '活': 1401, '派': 1402, '流': 1403, '浄': 1404, '浅': 1405, '浜': 1406, '浦': 1407, '浩': 1408, '浪': 1409, '浮': 1410, '浴': 1411, '海': 1412, '浸': 1413, '消': 1414, '涎': 1415, '涙': 1416, '涯': 1417, '液': 1418, '涼': 1419, '淀': 1420, '淋': 1421, '淘': 1422, '淡': 1423, '深': 1424, '淵': 1425, '混': 1426, '淹': 1427, '添': 1428, '清': 1429, '渇': 1430, '済': 1431, '渉': 1432, '渋': 1433, '渓': 1434, '減': 1435, '渡': 1436, '渦': 1437, '温': 1438, '測': 1439, '港': 1440, '渾': 1441, '湖': 1442, '湧': 1443, '湯': 1444, '湾': 1445, '湿': 1446, '満': 1447, '源': 1448, '準': 1449, '溜': 1450, '溝': 1451, '溢': 1452, '溶': 1453, '溺': 1454, '滅': 1455, '滋': 1456, '滑': 1457, '滝': 1458, '滞': 1459, '滴': 1460, '漁': 1461, '漂': 1462, '漆': 1463, '漏': 1464, '漑': 1465, '演': 1466, '漕': 1467, '漠': 1468, '漢': 1469, '漫': 1470, '漬': 1471, '潔': 1472, '潜': 1473, '潟': 1474, '潤': 1475, '潮': 1476, '潰': 1477, '激': 1478, '濁': 1479, '濃': 1480, '濡': 1481, '濫': 1482, '濯': 1483, '瀕': 1484, '瀞': 1485, '瀬': 1486, '灌': 1487, '灘': 1488, '火': 1489, '灯': 1490, '灰': 1491, '災': 1492, '炉': 1493, '炊': 1494, '炎': 1495, '炒': 1496, '炙': 1497, '炭': 1498, '点': 1499, '為': 1500, '烈': 1501, '烹': 1502, '焉': 1503, '焔': 1504, '無': 1505, '焦': 1506, '然': 1507, '焼': 1508, '煉': 1509, '煎': 1510, '煙': 1511, '照': 1512, '煮': 1513, '煽': 1514, '熊': 1515, '熟': 1516, '熱': 1517, '燃': 1518, '燈': 1519, '燐': 1520, '燕': 1521, '燥': 1522, '燻': 1523, '爆': 1524, '爪': 1525, '爬': 1526, '爵': 1527, '父': 1528, '爽': 1529, '片': 1530, '版': 1531, '牛': 1532, '牟': 1533, '牡': 1534, '牢': 1535, '牧': 1536, '物': 1537, '牲': 1538, '特': 1539, '牽': 1540, '犀': 1541, '犠': 1542, '犧': 1543, '犬': 1544, '犯': 1545, '状': 1546, '狂': 1547, '狐': 1548, '狙': 1549, '狛': 1550, '狩': 1551, '独': 1552, '狭': 1553, '狼': 1554, '猛': 1555, '猟': 1556, '猪': 1557, '猫': 1558, '献': 1559, '猶': 1560, '猿': 1561, '獄': 1562, '獅': 1563, '獣': 1564, '獲': 1565, '玄': 1566, '率': 1567, '玉': 1568, '王': 1569, '玖': 1570, '珂': 1571, '珍': 1572, '珠': 1573, '現': 1574, '球': 1575, '理': 1576, '琉': 1577, '琢': 1578, '琴': 1579, '瑞': 1580, '璧': 1581, '環': 1582, '瓦': 1583, '瓶': 1584, '甘': 1585, '生': 1586, '産': 1587, '甥': 1588, '用': 1589, '田': 1590, '由': 1591, '甲': 1592, '申': 1593, '男': 1594, '町': 1595, '画': 1596, '界': 1597, '畑': 1598, '留': 1599, '畜': 1600, '畢': 1601, '略': 1602, '番': 1603, '異': 1604, '畳': 1605, '畷': 1606, '疆': 1607, '疎': 1608, '疑': 1609, '疫': 1610, '疲': 1611, '疽': 1612, '疾': 1613, '病': 1614, '症': 1615, '痕': 1616, '痛': 1617, '痩': 1618, '痴': 1619, '痺': 1620, '瘍': 1621, '瘠': 1622, '療': 1623, '癌': 1624, '癒': 1625, '癖': 1626, '発': 1627, '登': 1628, '白': 1629, '百': 1630, '的': 1631, '皆': 1632, '皇': 1633, '皮': 1634, '皺': 1635, '皿': 1636, '盆': 1637, '益': 1638, '盗': 1639, '盛': 1640, '盟': 1641, '監': 1642, '盤': 1643, '目': 1644, '盲': 1645, '直': 1646, '相': 1647, '盾': 1648, '省': 1649, '眉': 1650, '看': 1651, '県': 1652, '真': 1653, '眠': 1654, '眸': 1655, '眺': 1656, '眼': 1657, '着': 1658, '睡': 1659, '督': 1660, '瞑': 1661, '瞬': 1662, '瞭': 1663, '瞳': 1664, '矛': 1665, '矢': 1666, '知': 1667, '短': 1668, '矮': 1669, '矯': 1670, '石': 1671, '砂': 1672, '研': 1673, '砕': 1674, '砥': 1675, '砦': 1676, '砲': 1677, '破': 1678, '硝': 1679, '硫': 1680, '硬': 1681, '碁': 1682, '碑': 1683, '碗': 1684, '碧': 1685, '確': 1686, '磁': 1687, '磐': 1688, '磨': 1689, '磯': 1690, '礎': 1691, '礫': 1692, '示': 1693, '礼': 1694, '社': 1695, '祈': 1696, '祖': 1697, '祝': 1698, '神': 1699, '祢': 1700, '祥': 1701, '票': 1702, '祭': 1703, '禁': 1704, '禍': 1705, '福': 1706, '禰': 1707, '秀': 1708, '私': 1709, '秋': 1710, '科': 1711, '秒': 1712, '秘': 1713, '秦': 1714, '秩': 1715, '称': 1716, '移': 1717, '稀': 1718, '程': 1719, '税': 1720, '稚': 1721, '種': 1722, '稲': 1723, '稼': 1724, '稽': 1725, '稿': 1726, '穀': 1727, '穂': 1728, '積': 1729, '穏': 1730, '穫': 1731, '穴': 1732, '究': 1733, '空': 1734, '突': 1735, '窒': 1736, '窓': 1737, '窟': 1738, '窮': 1739, '窯': 1740, '竈': 1741, '立': 1742, '竜': 1743, '竟': 1744, '章': 1745, '童': 1746, '端': 1747, '競': 1748, '竹': 1749, '笑': 1750, '笛': 1751, '笠': 1752, '符': 1753, '第': 1754, '笹': 1755, '筆': 1756, '筈': 1757, '等': 1758, '筋': 1759, '筑': 1760, '筒': 1761, '答': 1762, '策': 1763, '箇': 1764, '箋': 1765, '箔': 1766, '箕': 1767, '算': 1768, '管': 1769, '箱': 1770, '箸': 1771, '節': 1772, '範': 1773, '築': 1774, '篠': 1775, '篤': 1776, '簡': 1777, '籍': 1778, '米': 1779, '粉': 1780, '粋': 1781, '粒': 1782, '粗': 1783, '粘': 1784, '粟': 1785, '粧': 1786, '精': 1787, '糖': 1788, '糞': 1789, '糠': 1790, '糸': 1791, '系': 1792, '糾': 1793, '紀': 1794, '約': 1795, '紅': 1796, '紋': 1797, '納': 1798, '紐': 1799, '純': 1800, '紗': 1801, '紙': 1802, '級': 1803, '紛': 1804, '素': 1805, '索': 1806, '紫': 1807, '細': 1808, '紳': 1809, '紹': 1810, '終': 1811, '組': 1812, '絆': 1813, '経': 1814, '結': 1815, '絞': 1816, '絡': 1817, '給': 1818, '絨': 1819, '統': 1820, '絵': 1821, '絶': 1822, '絹': 1823, '継': 1824, '続': 1825, '綜': 1826, '維': 1827, '綱': 1828, '網': 1829, '綴': 1830, '綺': 1831, '綻': 1832, '綾': 1833, '綿': 1834, '緊': 1835, '総': 1836, '緑': 1837, '緒': 1838, '線': 1839, '締': 1840, '編': 1841, '緩': 1842, '練': 1843, '縁': 1844, '縄': 1845, '縛': 1846, '縞': 1847, '縦': 1848, '縫': 1849, '縮': 1850, '績': 1851, '繁': 1852, '繊': 1853, '繋': 1854, '織': 1855, '繕': 1856, '繰': 1857, '纂': 1858, '纏': 1859, '缶': 1860, '罠': 1861, '罪': 1862, '置': 1863, '罰': 1864, '署': 1865, '罵': 1866, '罹': 1867, '羅': 1868, '羊': 1869, '美': 1870, '群': 1871, '義': 1872, '羽': 1873, '翌': 1874, '習': 1875, '翔': 1876, '翻': 1877, '翼': 1878, '老': 1879, '考': 1880, '者': 1881, '耆': 1882, '而': 1883, '耐': 1884, '耕': 1885, '耗': 1886, '耳': 1887, '聖': 1888, '聞': 1889, '聴': 1890, '職': 1891, '肆': 1892, '肉': 1893, '肋': 1894, '肌': 1895, '肖': 1896, '肘': 1897, '肝': 1898, '股': 1899, '肢': 1900, '肥': 1901, '肩': 1902, '肪': 1903, '肯': 1904, '育': 1905, '肺': 1906, '胃': 1907, '胆': 1908, '背': 1909, '胎': 1910, '胞': 1911, '胱': 1912, '胴': 1913, '胸': 1914, '能': 1915, '脂': 1916, '脅': 1917, '脆': 1918, '脇': 1919, '脈': 1920, '脊': 1921, '脚': 1922, '脱': 1923, '脳': 1924, '脹': 1925, '腎': 1926, '腐': 1927, '腕': 1928, '腫': 1929, '腰': 1930, '腱': 1931, '腸': 1932, '腹': 1933, '腺': 1934, '腿': 1935, '膀': 1936, '膏': 1937, '膚': 1938, '膜': 1939, '膝': 1940, '膣': 1941, '膨': 1942, '膳': 1943, '膾': 1944, '膿': 1945, '臆': 1946, '臓': 1947, '臣': 1948, '臨': 1949, '自': 1950, '臭': 1951, '至': 1952, '致': 1953, '臼': 1954, '興': 1955, '舌': 1956, '舎': 1957, '舐': 1958, '舗': 1959, '舘': 1960, '舞': 1961, '舟': 1962, '航': 1963, '般': 1964, '舶': 1965, '船': 1966, '艇': 1967, '艘': 1968, '艦': 1969, '良': 1970, '色': 1971, '芋': 1972, '芝': 1973, '芦': 1974, '花': 1975, '芳': 1976, '芸': 1977, '芽': 1978, '苅': 1979, '苑': 1980, '苓': 1981, '苔': 1982, '苗': 1983, '若': 1984, '苦': 1985, '英': 1986, '苺': 1987, '茂': 1988, '茅': 1989, '茎': 1990, '茨': 1991, '茶': 1992, '茹': 1993, '草': 1994, '荊': 1995, '荒': 1996, '荘': 1997, '荷': 1998, '菊': 1999, '菌': 2000, '菓': 2001, '菜': 2002, '華': 2003, '菰': 2004, '菱': 2005, '萌': 2006, '萎': 2007, '萩': 2008, '落': 2009, '葉': 2010, '著': 2011, '葛': 2012, '董': 2013, '葦': 2014, '葬': 2015, '葺': 2016, '蒙': 2017, '蒲': 2018, '蒸': 2019, '蒼': 2020, '蓄': 2021, '蓋': 2022, '蓮': 2023, '蔑': 2024, '蔓': 2025, '蔗': 2026, '蔦': 2027, '蔭': 2028, '蔵': 2029, '蕎': 2030, '蕨': 2031, '薄': 2032, '薇': 2033, '薔': 2034, '薬': 2035, '藁': 2036, '藍': 2037, '藝': 2038, '藤': 2039, '藩': 2040, '蘇': 2041, '虐': 2042, '虚': 2043, '虜': 2044, '虫': 2045, '虹': 2046, '蚊': 2047, '蛇': 2048, '蛋': 2049, '蛍': 2050, '蛙': 2051, '蛮': 2052, '蜂': 2053, '蜃': 2054, '蜜': 2055, '蝉': 2056, '蝋': 2057, '蝶': 2058, '融': 2059, '蟲': 2060, '蟹': 2061, '蟻': 2062, '蠣': 2063, '血': 2064, '衆': 2065, '行': 2066, '術': 2067, '街': 2068, '衛': 2069, '衝': 2070, '衡': 2071, '衣': 2072, '表': 2073, '衰': 2074, '衾': 2075, '袋': 2076, '袖': 2077, '被': 2078, '袴': 2079, '裁': 2080, '裂': 2081, '装': 2082, '裏': 2083, '裕': 2084, '補': 2085, '裳': 2086, '裸': 2087, '製': 2088, '裾': 2089, '複': 2090, '褐': 2091, '褪': 2092, '襞': 2093, '襟': 2094, '襲': 2095, '西': 2096, '要': 2097, '覆': 2098, '覇': 2099, '見': 2100, '規': 2101, '視': 2102, '覗': 2103, '覚': 2104, '覧': 2105, '親': 2106, '観': 2107, '角': 2108, '解': 2109, '触': 2110, '言': 2111, '訂': 2112, '計': 2113, '訊': 2114, '討': 2115, '訓': 2116, '託': 2117, '記': 2118, '訛': 2119, '訟': 2120, '訣': 2121, '訪': 2122, '設': 2123, '許': 2124, '訳': 2125, '訴': 2126, '診': 2127, '証': 2128, '詐': 2129, '詑': 2130, '評': 2131, '詞': 2132, '詣': 2133, '試': 2134, '詩': 2135, '詫': 2136, '詰': 2137, '話': 2138, '詳': 2139, '誇': 2140, '誉': 2141, '誌': 2142, '認': 2143, '誑': 2144, '誓': 2145, '誕': 2146, '誘': 2147, '語': 2148, '誠': 2149, '誤': 2150, '誦': 2151, '説': 2152, '読': 2153, '誰': 2154, '課': 2155, '調': 2156, '談': 2157, '請': 2158, '諏': 2159, '論': 2160, '諦': 2161, '諸': 2162, '謀': 2163, '謂': 2164, '謎': 2165, '謖': 2166, '謙': 2167, '講': 2168, '謝': 2169, '謡': 2170, '謬': 2171, '識': 2172, '譜': 2173, '警': 2174, '議': 2175, '譲': 2176, '護': 2177, '讃': 2178, '讐': 2179, '谷': 2180, '豆': 2181, '豊': 2182, '豚': 2183, '象': 2184, '豪': 2185, '貌': 2186, '貝': 2187, '貞': 2188, '負': 2189, '財': 2190, '貢': 2191, '貧': 2192, '貨': 2193, '販': 2194, '貪': 2195, '貫': 2196, '責': 2197, '貯': 2198, '貰': 2199, '貴': 2200, '買': 2201, '貸': 2202, '費': 2203, '貼': 2204, '貿': 2205, '賀': 2206, '賂': 2207, '賃': 2208, '賄': 2209, '資': 2210, '賊': 2211, '賑': 2212, '賛': 2213, '賞': 2214, '賢': 2215, '質': 2216, '賭': 2217, '購': 2218, '贅': 2219, '贈': 2220, '贖': 2221, '赤': 2222, '赦': 2223, '走': 2224, '赴': 2225, '起': 2226, '超': 2227, '越': 2228, '趣': 2229, '趨': 2230, '足': 2231, '距': 2232, '跡': 2233, '跨': 2234, '路': 2235, '跳': 2236, '践': 2237, '踊': 2238, '踏': 2239, '蹄': 2240, '蹟': 2241, '蹴': 2242, '躁': 2243, '躍': 2244, '身': 2245, '車': 2246, '軋': 2247, '軌': 2248, '軍': 2249, '軒': 2250, '軟': 2251, '転': 2252, '軸': 2253, '軻': 2254, '軽': 2255, '較': 2256, '載': 2257, '輝': 2258, '輩': 2259, '輪': 2260, '輸': 2261, '輾': 2262, '轄': 2263, '辛': 2264, '辞': 2265, '辣': 2266, '辰': 2267, '辱': 2268, '農': 2269, '辺': 2270, '込': 2271, '迎': 2272, '近': 2273, '返': 2274, '迫': 2275, '述': 2276, '迷': 2277, '追': 2278, '退': 2279, '送': 2280, '逃': 2281, '逆': 2282, '透': 2283, '逐': 2284, '途': 2285, '逗': 2286, '這': 2287, '通': 2288, '速': 2289, '造': 2290, '逢': 2291, '連': 2292, '逮': 2293, '週': 2294, '進': 2295, '逸': 2296, '遂': 2297, '遅': 2298, '遇': 2299, '遊': 2300, '運': 2301, '遍': 2302, '過': 2303, '道': 2304, '達': 2305, '違': 2306, '遠': 2307, '遡': 2308, '遣': 2309, '遥': 2310, '適': 2311, '遭': 2312, '遮': 2313, '遷': 2314, '選': 2315, '遺': 2316, '遼': 2317, '避': 2318, '還': 2319, '那': 2320, '邦': 2321, '邪': 2322, '邸': 2323, '郊': 2324, '郎': 2325, '郡': 2326, '部': 2327, '郵': 2328, '郷': 2329, '都': 2330, '酋': 2331, '配': 2332, '酒': 2333, '酔': 2334, '酢': 2335, '酬': 2336, '酵': 2337, '酷': 2338, '酸': 2339, '醇': 2340, '醒': 2341, '醜': 2342, '醤': 2343, '醸': 2344, '采': 2345, '釈': 2346, '里': 2347, '重': 2348, '野': 2349, '量': 2350, '金': 2351, '釘': 2352, '針': 2353, '釣': 2354, '釧': 2355, '鈍': 2356, '鈴': 2357, '鉄': 2358, '鉛': 2359, '鉢': 2360, '鉱': 2361, '鉾': 2362, '銀': 2363, '銃': 2364, '銅': 2365, '銘': 2366, '銚': 2367, '銭': 2368, '鋤': 2369, '鋭': 2370, '鋼': 2371, '錆': 2372, '錠': 2373, '錦': 2374, '錨': 2375, '錬': 2376, '録': 2377, '鍋': 2378, '鍛': 2379, '鍵': 2380, '鎌': 2381, '鎖': 2382, '鎮': 2383, '鏡': 2384, '鐘': 2385, '鑑': 2386, '長': 2387, '門': 2388, '閃': 2389, '閉': 2390, '開': 2391, '閑': 2392, '間': 2393, '関': 2394, '閣': 2395, '閥': 2396, '閲': 2397, '闇': 2398, '闘': 2399, '阜': 2400, '阪': 2401, '防': 2402, '阻': 2403, '阿': 2404, '附': 2405, '降': 2406, '限': 2407, '陛': 2408, '陝': 2409, '院': 2410, '陣': 2411, '除': 2412, '陥': 2413, '陰': 2414, '陳': 2415, '陵': 2416, '陶': 2417, '陸': 2418, '険': 2419, '陽': 2420, '隅': 2421, '隊': 2422, '階': 2423, '随': 2424, '隔': 2425, '隕': 2426, '隙': 2427, '際': 2428, '障': 2429, '隠': 2430, '隣': 2431, '隷': 2432, '隻': 2433, '雀': 2434, '雄': 2435, '雅': 2436, '集': 2437, '雇': 2438, '雌': 2439, '雑': 2440, '離': 2441, '難': 2442, '雨': 2443, '雪': 2444, '雰': 2445, '雲': 2446, '零': 2447, '雷': 2448, '電': 2449, '需': 2450, '震': 2451, '霊': 2452, '霞': 2453, '霧': 2454, '露': 2455, '霹': 2456, '靂': 2457, '青': 2458, '静': 2459, '非': 2460, '面': 2461, '革': 2462, '靴': 2463, '鞄': 2464, '鞍': 2465, '鞘': 2466, '鞠': 2467, '鞭': 2468, '韓': 2469, '音': 2470, '韻': 2471, '響': 2472, '頂': 2473, '頃': 2474, '項': 2475, '順': 2476, '須': 2477, '預': 2478, '頑': 2479, '頓': 2480, '頗': 2481, '領': 2482, '頬': 2483, '頭': 2484, '頷': 2485, '頸': 2486, '頻': 2487, '頼': 2488, '顆': 2489, '題': 2490, '額': 2491, '顔': 2492, '顕': 2493, '願': 2494, '類': 2495, '顧': 2496, '風': 2497, '飄': 2498, '飛': 2499, '飜': 2500, '食': 2501, '飢': 2502, '飯': 2503, '飲': 2504, '飴': 2505, '飼': 2506, '飽': 2507, '飾': 2508, '餃': 2509, '餅': 2510, '養': 2511, '餌': 2512, '餐': 2513, '餓': 2514, '館': 2515, '饉': 2516, '首': 2517, '香': 2518, '馬': 2519, '馭': 2520, '馳': 2521, '馴': 2522, '駄': 2523, '駅': 2524, '駆': 2525, '駈': 2526, '駐': 2527, '駒': 2528, '駿': 2529, '騎': 2530, '騒': 2531, '験': 2532, '騰': 2533, '驚': 2534, '骨': 2535, '骸': 2536, '高': 2537, '髣': 2538, '髪': 2539, '髭': 2540, '髴': 2541, '鬱': 2542, '鬼': 2543, '魂': 2544, '魅': 2545, '魔': 2546, '魚': 2547, '鮫': 2548, '鮭': 2549, '鮮': 2550, '鯛': 2551, '鯨': 2552, '鰐': 2553, '鰓': 2554, '鰻': 2555, '鳥': 2556, '鳩': 2557, '鳴': 2558, '鴨': 2559, '鵜': 2560, '鶏': 2561, '鶯': 2562, '鶴': 2563, '鷲': 2564, '鷹': 2565, '鸞': 2566, '鹸': 2567, '鹿': 2568, '麗': 2569, '麦': 2570, '麺': 2571, '麻': 2572, '黄': 2573, '黒': 2574, '黙': 2575, '鼓': 2576, '鼠': 2577, '鼻': 2578, '鼾': 2579, '齢': 2580, '齧': 2581, '龍': 2582, '＆': 2583, '－': 2584, '．': 2585, '／': 2586, '＝': 2587, '＼': 2588, '＾': 2589, 'ａ': 2590, 'ｂ': 2591, 'ｄ': 2592, 'ｆ': 2593, 'ｇ': 2594, 'ｈ': 2595, 'ｊ': 2596, 'ｋ': 2597, 'ｎ': 2598, 'ｏ': 2599, 'ｐ': 2600, 'ｒ': 2601, 'ｓ': 2602, 'ｔ': 2603, 'ｕ': 2604, 'ｖ': 2605, 'ｙ': 2606, '｢': 2607, '｣': 2608, '･': 2609}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_dict[\"^\"] = vocab_dict[\" \"] # | is a valid punctuation in bengali, equivalent to full stop (\".\")\n",
        "del vocab_dict[\" \"]"
      ],
      "metadata": {
        "id": "YVdVYtOevhGn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# truncating the test set size to 1024\n",
        "if len(common_voice_test) > 1024:\n",
        "    common_voice_test_full = common_voice_test\n",
        "    common_voice_test = common_voice_test.select(range(1024))"
      ],
      "metadata": {
        "id": "tKLvFj0FucDF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6yNHhMjYub3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Speaker ID processing***"
      ],
      "metadata": {
        "id": "G5ZszKA7ruW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "speaker_ids_train = [common_voice_train[i][\"client_id\"] for i in range(len(common_voice_train))]\n",
        "#speaker_ids_test = common_voice_test.features[\"speaker_id\"].feature.names"
      ],
      "metadata": {
        "id": "_cowkccdmt1o"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of unique strings\n",
        "speaker_ids_unique = sorted(set(speaker_ids_train))"
      ],
      "metadata": {
        "id": "_nM8iPhcoQsf"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## map the speaker ids to the corresponding labels\n",
        "speaker_id_map = {speaker_id: i for i, speaker_id in enumerate(speaker_ids_unique)}"
      ],
      "metadata": {
        "id": "Bf7Jo0ZEnzxn"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(speaker_ids_unique[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTWUuxmn6N7t",
        "outputId": "182eea66-6478-43bc-e51b-1e49c0a8c7f0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Prepare data loader***"
      ],
      "metadata": {
        "id": "sigcWEdEvukJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", language=\"Japanese\", task=\"transcribe\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXv-VLjfvu8A",
        "outputId": "51f243cb-16f5-4d40-8b6d-d7568a9345e0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(batch):\n",
        "    audio = batch[\"audio\"]\n",
        "\n",
        "    # batched output is \"un-batched\"\n",
        "    batch[\"input_values\"] = audio[\"array\"]\n",
        "    batch[\"input_length\"] = len(batch[\"input_values\"])\n",
        "    batch[\"word_labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n",
        "    batch[\"client_id\"] = batch[\"client_id\"].split(\"\\n\")\n",
        "    #print(batch[\"client_id\"])\n",
        "    #batch[\"client_id\"] = batch[\"client_id\"].tolist()\n",
        "    # batch[\"speaker_labels\"] = []\n",
        "    # for i, id in enumerate(batch[\"client_id\"]):\n",
        "    #   print(id)\n",
        "    #   print(speaker_id_map[id])\n",
        "    #   batch[\"speaker_labels\"].append(speaker_id_map[id])\n",
        "    batch[\"speaker_labels\"] = [speaker_id_map[speaker_id] for speaker_id in batch[\"client_id\"]]\n",
        "    return batch"
      ],
      "metadata": {
        "id": "DpaGUWA5vuK4"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Speaker IDs in the train data does not always match speaker id in the test data"
      ],
      "metadata": {
        "id": "akbLwAo67XTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "common_voice_train = common_voice_train.map(prepare_dataset, remove_columns=common_voice_train.column_names)\n",
        "# common_voice_test_1 = common_voice_test.map(prepare_dataset, remove_columns=common_voice_test.column_names)"
      ],
      "metadata": {
        "id": "JjXs-ZEczt3P"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filtering out longer inputs\n",
        "max_input_length_in_sec = 5.0\n",
        "sampling_rate = 16000\n",
        "\n",
        "common_voice_train = common_voice_train.filter(\n",
        "    lambda x: x < max_input_length_in_sec * sampling_rate,\n",
        "    input_columns=[\"input_length\"]\n",
        ")\n",
        "print(len(common_voice_train))\n",
        "\n",
        "duration = 0\n",
        "for i in range(len(common_voice_train)):\n",
        "    duration += common_voice_train[i][\"input_length\"] / sampling_rate\n",
        "print(f\"Train set duration: {duration / 3600:.2f} hours\")\n",
        "\n",
        "common_voice_test = common_voice_test.filter(\n",
        "    lambda x: x < max_input_length_in_sec * sampling_rate,\n",
        "    input_columns=[\"input_length\"]\n",
        ")\n",
        "print(len(common_voice_test))"
      ],
      "metadata": {
        "id": "pynkTSs0tKq4",
        "outputId": "7721d03e-dcce-4c13-d87f-57a9dd88512b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450,
          "referenced_widgets": [
            "afc4be00c6b146f49eb9ef44b5f2e1ea",
            "68bd2d2c0eec47f3b0c25d194fcf8c98",
            "62e40b5ae8404959bfac95e80f8fdf6e",
            "94343271cf6043fab5ae13ddba0a01a6",
            "e5012495a3da46d681e39fa1496762e2",
            "13dab129701a4f0f85732415ec89d4b0",
            "8b0e2bdb6c72490e8e2944af73f6917a",
            "87b13601ac8b4e21a671c9c73cca6f97",
            "61345534f8e64c16aa550f0adb14aba4",
            "1eb370cfb56945b9b3651a4692e9269d",
            "06035622c9a948f2a9ae25da9ec95622"
          ]
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/10039 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "afc4be00c6b146f49eb9ef44b5f2e1ea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5993\n",
            "Train set duration: 6.28 hours\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input column ['input_length'] not in the dataset. Current columns in the dataset: ['client_id', 'path', 'audio', 'sentence', 'variant']",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-11b21d3a412e>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Train set duration: {duration / 3600:.2f} hours\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m common_voice_test = common_voice_test.filter(\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_input_length_in_sec\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msampling_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0minput_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_length\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m         }\n\u001b[1;32m    566\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;31m# re-apply format to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/fingerprint.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0;31m# Call actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m             \u001b[0;31m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3707\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3709\u001b[0;31m         indices = self.map(\n\u001b[0m\u001b[1;32m   3710\u001b[0m             function=partial(\n\u001b[1;32m   3711\u001b[0m                 \u001b[0mget_indices_from_mask_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Dataset\"\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"self\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m         }\n\u001b[1;32m    566\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;31m# re-apply format to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3064\u001b[0m             \u001b[0mmissing_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_columns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   3067\u001b[0m                     \u001b[0;34mf\"Input column {list(missing_columns)} not in the dataset. Current columns in the dataset: {self._data.column_names}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m                 )\n",
            "\u001b[0;31mValueError\u001b[0m: Input column ['input_length'] not in the dataset. Current columns in the dataset: ['client_id', 'path', 'audio', 'sentence', 'variant']"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Define Data collator***"
      ],
      "metadata": {
        "id": "bQFjauR_8_EM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Union\n",
        "\n",
        "from transformers import WhisperProcessor\n",
        "\n",
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"Japanese\", task=\"transcribe\")\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorSpeechSeq2SeqWithPadding:\n",
        "    processor: processor\n",
        "    decoder_start_token_id: int\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
        "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
        "        # first treat the audio inputs by simply returning torch tensors\n",
        "        input_features = [{\"input_features\": feature[\"input_values\"]} for feature in features]\n",
        "        # print(input_features.keys())\n",
        "        #pad the inputs to max length\n",
        "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
        "\n",
        "        # get the tokenized label sequences\n",
        "        label_features = [{\"input_ids\": feature[\"word_labels\"]} for feature in features]\n",
        "        # pad the labels to max length\n",
        "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
        "\n",
        "        # replace padding with -100 to ignore loss correctly\n",
        "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
        "\n",
        "        # if bos token is appended in previous tokenization step,\n",
        "        # cut bos token here as it's append later anyways\n",
        "        if (labels[:, 0] == self.decoder_start_token_id).all().cpu().item():\n",
        "            labels = labels[:, 1:]\n",
        "\n",
        "        batch[\"word_labels\"] = labels\n",
        "\n",
        "        return batch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y31LGcJR88v3",
        "outputId": "12665b47-17f8-4741-e6f1-4aababaf076e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_whisper = WhisperModel.from_pretrained(\"openai/whisper-base\")\n",
        "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor, decoder_start_token_id=model_whisper.config.decoder_start_token_id)"
      ],
      "metadata": {
        "id": "7qDJIbc6RUVB"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(common_voice_train, batch_size=32, shuffle=True, collate_fn=data_collator)\n",
        "for batch in train_dataloader:\n",
        "    break\n",
        "\n",
        "print({k:v.shape for k,v in batch.items()})"
      ],
      "metadata": {
        "id": "0D1YOYavSa8K",
        "outputId": "8b62b4b5-981b-43a5-dbd0-78d17a3a4cbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "operands could not be broadcast together with remapped shapes [original->remapped]: (2,2)  and requested shape (1,2)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-53aee83679e8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommon_voice_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_collator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-48-b60bff3c6241>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# print(input_features.keys())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m#pad the inputs to max length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# get the tokenized label sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/feature_extraction_sequence_utils.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(self, processed_features, padding, max_length, truncation, pad_to_multiple_of, return_attention_mask, return_tensors)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0;31m# padding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             outputs = self._pad(\n\u001b[0m\u001b[1;32m    210\u001b[0m                 \u001b[0mtruncated_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/feature_extraction_sequence_utils.py\u001b[0m in \u001b[0;36m_pad\u001b[0;34m(self, processed_features, max_length, padding_strategy, pad_to_multiple_of, return_attention_mask)\u001b[0m\n\u001b[1;32m    279\u001b[0m                     )\n\u001b[1;32m    280\u001b[0m                 \u001b[0mpadding_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdifference\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdifference\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m                 processed_features[self.model_input_names[0]] = np.pad(\n\u001b[0m\u001b[1;32m    282\u001b[0m                     \u001b[0mrequired_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"constant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstant_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/arraypad.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(array, pad_width, mode, **kwargs)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[0;31m# Broadcast to shape (array.ndim, 2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m     \u001b[0mpad_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_as_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/arraypad.py\u001b[0m in \u001b[0;36m_as_pairs\u001b[0;34m(x, ndim, as_index)\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0;31m# Converting the array with `tolist` seems to improve performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;31m# when iterating and indexing the result (see usage in `pad`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/stride_tricks.py\u001b[0m in \u001b[0;36mbroadcast_to\u001b[0;34m(array, shape, subok)\u001b[0m\n\u001b[1;32m    411\u001b[0m            [1, 2, 3]])\n\u001b[1;32m    412\u001b[0m     \"\"\"\n\u001b[0;32m--> 413\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_broadcast_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/stride_tricks.py\u001b[0m in \u001b[0;36m_broadcast_to\u001b[0;34m(array, shape, subok, readonly)\u001b[0m\n\u001b[1;32m    347\u001b[0m                          'negative')\n\u001b[1;32m    348\u001b[0m     \u001b[0mextras\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m     it = np.nditer(\n\u001b[0m\u001b[1;32m    350\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'multi_index'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'refs_ok'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'zerosize_ok'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextras\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         op_flags=['readonly'], itershape=shape, order='C')\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with remapped shapes [original->remapped]: (2,2)  and requested shape (1,2)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Defining evaluation matrices***"
      ],
      "metadata": {
        "id": "BMyVqirnR2tT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric = load_metric(\"wer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lc1Od0RkR2RH",
        "outputId": "62c42fb2-9708-4db9-dae7-0b6b219738c2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-b35977d54776>:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"wer\")\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for wer contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/wer/wer.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "    pred_ids = pred.predictions\n",
        "    label_ids = pred.label_ids\n",
        "\n",
        "    # replace -100 with the pad_token_id\n",
        "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
        "\n",
        "    # we do not want to group tokens when computing the metrics\n",
        "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
        "\n",
        "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
        "\n",
        "    return {\"wer\": wer}\n"
      ],
      "metadata": {
        "id": "0I1nYKNjR2J8"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***MODEL BUILDING***"
      ],
      "metadata": {
        "id": "_kS_9zSCmcIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## ECAPA encoding\n",
        "# classifier = EncoderClassifier.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\")\n",
        "# signal = common_voice_train[0][\"audio\"][\"array\"]\n",
        "# # fs = common_voice_train[0][\"audio\"][\"sampling_rate\"]\n",
        "# embeddings = classifier.encode_batch(torch.tensor(signal))\n",
        "\n",
        "# ## Whisper Encoding\n",
        "# model = WhisperModel.from_pretrained(\"openai/whisper-base\")\n",
        "# feature_extractor = AutoFeatureExtractor.from_pretrained(\"openai/whisper-base\")\n",
        "\n",
        "# inputs = feature_extractor(common_voice_train[0][\"audio\"][\"array\"], sampling_rate=common_voice_train[0][\"audio\"][\"sampling_rate\"], return_tensors=\"pt\")\n",
        "# input_features = inputs.input_features\n",
        "# decoder_input_ids = torch.tensor([[1, 1]]) * model.config.decoder_start_token_id\n",
        "# last_hidden_state = model(input_features, decoder_input_ids=decoder_input_ids).encoder_last_hidden_state\n",
        "# list(last_hidden_state.shape)"
      ],
      "metadata": {
        "id": "BEnpfJ7dhL_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_input_ids = torch.tensor([[1, 1]]) * model_whisper.config.decoder_start_token_id\n",
        "decoder_input_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8KAV-XgC0wL",
        "outputId": "d99a2c94-82b1-4365-80e1-4d4df4676be4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[50258, 50258]])"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "last_hidden_state = model(input_features, decoder_input_ids=decoder_input_ids)"
      ],
      "metadata": {
        "id": "ACbFNYRzd9IK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sV6gH57KcxKB",
        "outputId": "5f6aca5f-d221-4419-948c-751fd7a838e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WhisperModel(\n",
              "  (encoder): WhisperEncoder(\n",
              "    (conv1): Conv1d(80, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,))\n",
              "    (embed_positions): Embedding(1500, 512)\n",
              "    (layers): ModuleList(\n",
              "      (0-5): 6 x WhisperEncoderLayer(\n",
              "        (self_attn): WhisperSdpaAttention(\n",
              "          (k_proj): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (activation_fn): GELUActivation()\n",
              "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (decoder): WhisperDecoder(\n",
              "    (embed_tokens): Embedding(51865, 512, padding_idx=50257)\n",
              "    (embed_positions): WhisperPositionalEmbedding(448, 512)\n",
              "    (layers): ModuleList(\n",
              "      (0-5): 6 x WhisperDecoderLayer(\n",
              "        (self_attn): WhisperSdpaAttention(\n",
              "          (k_proj): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (activation_fn): GELUActivation()\n",
              "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (encoder_attn): WhisperSdpaAttention(\n",
              "          (k_proj): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embedding shape from Whisper: Batch X 1500 X 512 --> Batch X 1500 X 64\n",
        "\n",
        "Embedding shape from ECAPA: Batch X 1 X 192 --> Batch X 1 X 64"
      ],
      "metadata": {
        "id": "k5ji-K_cDSIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your downsampling convolutional layer\n",
        "downsample_conv = nn.Conv1d(in_channels=512, out_channels=64, kernel_size=1)\n",
        "\n",
        "# Assuming your input tensor is named input_tensor\n",
        "# Reshape the tensor to fit the convolutional layer\n",
        "input_tensor = torch.ones(2,1500,512)\n",
        "input_tensor = input_tensor.permute(0, 2, 1)  # Change shape to batch * 512 * 1500\n",
        "\n",
        "# Apply convolution\n",
        "output_tensor = downsample_conv(input_tensor)\n",
        "\n",
        "# Check the shape\n",
        "print(output_tensor.shape)  # Should be batch * 64 * 500\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABzUMbg5Eadd",
        "outputId": "3b4b5d81-d193-4114-f2c2-007107218abe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 64, 1500])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(2, 1500, 512)\n",
        "x = torch.mean(x,dim=1)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6vIVS52YQWQ",
        "outputId": "431c694b-ee86-466c-b351-0e4f1fdf2e45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "WFP5lUMNuj0W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "735d9ac8-220a-4a94-beb0-b8757da3eca9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1486: FutureWarning: The repository for hf-internal-testing/librispeech_asr_dummy contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hf-internal-testing/librispeech_asr_dummy\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 2610])\n",
            "torch.Size([1, 578])\n"
          ]
        }
      ],
      "source": [
        "class SpeechModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SpeechModel, self).__init__()\n",
        "        self.sampling_rate = 16000\n",
        "        self.num_speaker_class = 578 # change this after analyzing dataset\n",
        "        self.word_vocab = 2610 # change this after analyzing dataset -> len(vocab_dict)\n",
        "        self.whisper_encoder = WhisperModel.from_pretrained(\"openai/whisper-base\")\n",
        "        self.decoder_input_ids = torch.tensor([[1, 1]]) * self.whisper_encoder.config.decoder_start_token_id\n",
        "        self.whisper_feature_extractor = AutoFeatureExtractor.from_pretrained(\"openai/whisper-base\")\n",
        "        self.ecapa_encoder = EncoderClassifier.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\")\n",
        "\n",
        "        # Define downsampling layers\n",
        "        self.whisper_downsample = nn.Conv1d(in_channels=512, out_channels=64, kernel_size=1)\n",
        "        self.ecapa_downsample = nn.Conv1d(in_channels=192, out_channels=64, kernel_size=1)\n",
        "\n",
        "        # Define Transformer layers\n",
        "        self.transformer_encoder_single = nn.TransformerEncoderLayer(d_model=128, nhead=8, dim_feedforward=512, batch_first=True)\n",
        "        self.transformer_decoder_single = nn.TransformerDecoderLayer(d_model=128, nhead=8, dim_feedforward=512, batch_first=True)\n",
        "        self.transformer_encoder_stack = nn.TransformerEncoder(self.transformer_encoder_single, num_layers=6)\n",
        "        self.transformer_decoder_stack = nn.TransformerDecoder(self.transformer_decoder_single, num_layers=6)\n",
        "\n",
        "        self.decoder_input_ids = torch.tensor([[1, 1]]) * self.whisper_encoder.config.decoder_start_token_id\n",
        "\n",
        "        # Define prediction heads\n",
        "        self.next_word_prediction_head = nn.Linear(128,self.word_vocab)\n",
        "        self.speaker_recognition_head = nn.Linear(128,self.num_speaker_class)\n",
        "        self.speaker_softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass for whisper branch\n",
        "        x_whisper = self.whisper_feature_extractor(x, sampling_rate=self.sampling_rate, return_tensors=\"pt\").input_features\n",
        "        whisper_embedding = self.whisper_encoder(x_whisper, decoder_input_ids=self.decoder_input_ids).encoder_last_hidden_state\n",
        "        whisper_embedding = whisper_embedding.permute(0, 2, 1)\n",
        "        downsampled_whisper_embedding = self.whisper_downsample(whisper_embedding)\n",
        "        downsampled_whisper_embedding = downsampled_whisper_embedding.permute(0, 2, 1)\n",
        "        downsampled_whisper_embedding = torch.mean(downsampled_whisper_embedding, dim=1)\n",
        "\n",
        "        # Forward pass for ECAPA branch\n",
        "        ecapa_embedding = self.ecapa_encoder.encode_batch(x)\n",
        "        ecapa_embedding = ecapa_embedding.permute(0, 2, 1)\n",
        "        downsampled_ecapa_embedding = self.ecapa_downsample(ecapa_embedding)\n",
        "        downsampled_ecapa_embedding = downsampled_ecapa_embedding.permute(0, 2, 1)\n",
        "        downsampled_ecapa_embedding = torch.squeeze(downsampled_ecapa_embedding,dim=1)\n",
        "\n",
        "        # Concatenate downscaled embeddings\n",
        "        concatenated_embeddings = torch.cat((downsampled_whisper_embedding, downsampled_ecapa_embedding), dim=-1)\n",
        "\n",
        "        # Transformer layers\n",
        "        transformer_output = self.transformer_encoder_stack(concatenated_embeddings)\n",
        "        #transformer_decoder_output = self.transformer_decoder_stack(self.decoder_input_ids, transformer_output)\n",
        "        transformer_decoder_output = self.transformer_decoder_stack(concatenated_embeddings, transformer_output)\n",
        "\n",
        "        # Task-specific heads\n",
        "        word_prediction = self.next_word_prediction_head(transformer_decoder_output)\n",
        "        speaker_recognition = self.speaker_recognition_head(transformer_output)\n",
        "        speaker_recognition = self.speaker_softmax(speaker_recognition)\n",
        "\n",
        "        #next_word_prediction = self.next_word_prediction_head(transformer_output\n",
        "\n",
        "        return word_prediction, speaker_recognition\n",
        "\n",
        "# Define model\n",
        "model = SpeechModel()\n",
        "ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
        "input_data = torch.tensor(ds[0][\"audio\"][\"array\"])\n",
        "output_word, output_speaker = model.forward(input_data)\n",
        "print(output_word.shape)\n",
        "print(output_speaker.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss functions\n",
        "next_word_loss_function = nn.CTCLoss()\n",
        "speaker_recognition_loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Load dataset\n",
        "# dataset = CommonVoiceDataset(root_dir='path_to_commonvoice_dataset', transform=transform)\n",
        "\n",
        "# # Training loop\n",
        "# num_epochs = 3\n",
        "# for epoch in range(num_epochs):\n",
        "#     for batch in dataloader:\n",
        "#         optimizer.zero_grad()\n",
        "#         inputs, targets = batch\n",
        "#         next_word_prediction, speaker_recognition = model(inputs)\n",
        "\n",
        "#         # Calculate loss\n",
        "#         next_word_loss = next_word_loss_function(next_word_prediction, targets)\n",
        "#         # Calculate speaker recognition loss\n",
        "#         speaker_recognition_loss = speaker_recognition_loss_function(speaker_recognition, speaker_labels)\n",
        "\n",
        "#         total_loss = next_word_loss + speaker_recognition_loss\n",
        "\n",
        "#         # Backpropagation\n",
        "#         total_loss.backward()\n",
        "#         optimizer.step()"
      ],
      "metadata": {
        "id": "3iAhAS2_LM_k",
        "outputId": "2666a253-1ddd-4f51-bafb-ab5d1b0d378c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "each element in list of batch should be of equal size",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-f8f63df556c6>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \"\"\"\n\u001b[0;32m--> 277\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;31m# The mapping type may not support `__init__(iterable)`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;31m# The mapping type may not support `__init__(iterable)`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0melem_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0melem_size\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# It may be accessed twice, so we use a list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: each element in list of batch should be of equal size"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "common_voice_train"
      ],
      "metadata": {
        "id": "aroksHCzwCX6",
        "outputId": "bc3e32c9-dc93-452d-8cb3-46c9e95912d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_values', 'input_length', 'word_labels', 'speaker_labels'],\n",
              "    num_rows: 10039\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "common_voice_train['input_length'][9]"
      ],
      "metadata": {
        "id": "S6fjuQk0wRwK",
        "outputId": "f55a7919-6259-44be-c308-dcf598860e6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50304"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RnObEVo0QsHq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}